# Claude Skill: Distributed Systems Design Principles

**Purpose**: Guide the design and implementation of distributed systems with focus on reliability, repeatability, and fault tolerance.

---

## Core Principle

**Distributed systems MUST be designed for failure, idempotency, and eventual consistency.**

**Rationale**:
- Networks are unreliable - messages can be lost, duplicated, or delayed
- Services can crash at any time - partial failures are the norm
- Clocks are not synchronized - ordering cannot be assumed
- State must be eventually consistent - immediate consistency is impossible at scale
- Operations must be repeatable - retries are essential for reliability

---

## Fundamental Distributed Systems Principles

### 1. Idempotency

**Rule**: Every operation MUST be safely repeatable without changing the result beyond the initial application.

**Why Critical**:
- Network failures cause retries
- Message brokers may deliver duplicates
- Clients may retry on timeout (even if server processed it)
- Crash recovery requires replaying operations

**Implementation Patterns**:

#### Pattern 1: Idempotency Keys (API Requests)

```typescript
// HTTP API with idempotency key
interface CreateBattleRequest {
  idempotencyKey: string; // UUID generated by client
  systemId: bigint;
  startTime: Date;
  // ... other fields
}

// Service implementation
class BattleService {
  async createBattle(request: CreateBattleRequest): Promise<Battle> {
    // Check if already processed
    const existing = await this.idempotencyStore.get(request.idempotencyKey);
    if (existing) {
      logger.info('Duplicate request detected, returning existing battle', {
        idempotencyKey: request.idempotencyKey,
        battleId: existing.battleId,
      });
      return existing.result;
    }

    // Process request
    const battle = await this.battleRepository.create({
      id: uuidv4(),
      systemId: request.systemId,
      startTime: request.startTime,
      // ...
    });

    // Store idempotency record
    await this.idempotencyStore.set(request.idempotencyKey, {
      battleId: battle.id,
      result: battle,
      processedAt: new Date(),
    }, { ttl: 86400 }); // 24 hour retention

    return battle;
  }
}

// Idempotency store implementation
interface IdempotencyStore {
  async get(key: string): Promise<{ result: any; processedAt: Date } | null>;
  async set(key: string, value: any, options?: { ttl: number }): Promise<void>;
}

// Redis implementation
class RedisIdempotencyStore implements IdempotencyStore {
  constructor(private redis: Redis) {}

  async get(key: string) {
    const value = await this.redis.get(`idempotency:${key}`);
    return value ? JSON.parse(value) : null;
  }

  async set(key: string, value: any, options?: { ttl: number }) {
    const serialized = JSON.stringify(value);
    if (options?.ttl) {
      await this.redis.setex(`idempotency:${key}`, options.ttl, serialized);
    } else {
      await this.redis.set(`idempotency:${key}`, serialized);
    }
  }
}
```

#### Pattern 2: Natural Idempotency (Database Constraints)

```typescript
// Use unique constraints for natural idempotency
class KillmailRepository {
  async insert(killmail: KillmailEventRecord): Promise<void> {
    try {
      await this.db
        .insertInto('killmail_events')
        .values({
          killmailId: killmail.killmailId, // PRIMARY KEY
          occurredAt: killmail.occurredAt,
          systemId: killmail.systemId,
          // ...
        })
        .execute();
    } catch (error) {
      // Duplicate key error - already processed
      if (isDuplicateKeyError(error)) {
        logger.info('Killmail already ingested, skipping', {
          killmailId: killmail.killmailId,
        });
        return; // Idempotent - no-op
      }
      throw error;
    }
  }
}

// Battle participant with composite unique key
await this.db
  .insertInto('battle_participants')
  .values({
    battleId,
    characterId, // Composite unique key (battleId, characterId)
    side,
    kills: sql`1`, // Initial value
  })
  .onConflict((oc) =>
    oc.columns(['battleId', 'characterId']).doUpdateSet({
      kills: sql`battle_participants.kills + 1`, // Increment on duplicate
    })
  )
  .execute();
```

#### Pattern 3: Event Deduplication (Kafka/Message Bus)

```typescript
// Event with deduplication ID
interface BattleCreatedEvent {
  eventId: string; // UUID - unique per event instance
  eventType: 'battle.created';
  eventVersion: string;
  timestamp: string;
  data: {
    battleId: string;
    // ...
  };
}

// Consumer with deduplication
class BattleCreatedConsumer {
  private processedEvents = new Set<string>(); // In-memory cache
  private readonly redis: Redis;

  async handle(event: BattleCreatedEvent): Promise<void> {
    // Check if already processed (in-memory)
    if (this.processedEvents.has(event.eventId)) {
      logger.info('Duplicate event detected (memory), skipping', {
        eventId: event.eventId,
      });
      return;
    }

    // Check if already processed (persistent store)
    const processed = await this.redis.get(`event:processed:${event.eventId}`);
    if (processed) {
      logger.info('Duplicate event detected (redis), skipping', {
        eventId: event.eventId,
      });
      this.processedEvents.add(event.eventId); // Update cache
      return;
    }

    try {
      // Process event
      await this.indexBattleInSearchEngine(event.data);

      // Mark as processed
      await this.redis.setex(
        `event:processed:${event.eventId}`,
        86400, // 24 hour TTL
        new Date().toISOString(),
      );
      this.processedEvents.add(event.eventId);

      logger.info('Event processed successfully', { eventId: event.eventId });
    } catch (error) {
      logger.error('Event processing failed', { eventId: event.eventId, error });
      throw error; // Retry via Kafka consumer group
    }
  }
}
```

---

### 2. At-Least-Once Delivery

**Rule**: Message delivery guarantees should be at-least-once, with idempotent handling to ensure exactly-once semantics.

**Why Critical**:
- At-most-once loses data (unacceptable)
- Exactly-once is theoretically impossible in distributed systems
- At-least-once + idempotency = effectively exactly-once

**Kafka Consumer Pattern**:

```typescript
class KafkaEventConsumer {
  private consumer: Consumer;

  async start(): Promise<void> {
    await this.consumer.subscribe({ topic: 'battle.created' });

    await this.consumer.run({
      // Process each message
      eachMessage: async ({ topic, partition, message }) => {
        const event = JSON.parse(message.value!.toString());

        try {
          // Process with idempotent handler
          await this.handleEvent(event);

          // IMPORTANT: Only commit offset AFTER successful processing
          // This ensures at-least-once delivery
          // If processing fails, message will be redelivered
        } catch (error) {
          logger.error('Event processing failed, will retry', {
            topic,
            partition,
            offset: message.offset,
            error,
          });

          // Option 1: Throw to retry immediately
          throw error;

          // Option 2: Send to dead letter queue
          // await this.deadLetterQueue.send(event);
          // Don't throw - commit offset to skip this message
        }
      },

      // Auto-commit offset after processing (default behavior)
      // Ensures at-least-once delivery semantics
      autoCommit: true,
      autoCommitInterval: 5000,
    });
  }

  private async handleEvent(event: BattleCreatedEvent): Promise<void> {
    // Idempotent processing
    if (await this.isAlreadyProcessed(event.eventId)) {
      return; // Skip duplicates
    }

    // Process event
    await this.businessLogic(event);

    // Mark as processed
    await this.markProcessed(event.eventId);
  }
}
```

---

### 3. Eventual Consistency

**Rule**: Accept that distributed data will be eventually consistent, not immediately consistent.

**Why Critical**:
- CAP theorem: Can't have Consistency + Availability + Partition tolerance
- Network partitions are unavoidable
- Immediate consistency requires distributed transactions (slow, complex, fragile)

**Implementation Patterns**:

#### Pattern 1: Event Sourcing for Consistency

```typescript
// Clusterer Service creates battle (source of truth)
class ClustererService {
  async createBattle(killmails: KillmailEventRecord[]): Promise<Battle> {
    // Write to own database (immediate consistency)
    const battle = await this.battleRepository.create({
      id: uuidv4(),
      systemId: killmails[0].systemId,
      startTime: new Date(Math.min(...killmails.map(k => k.occurredAt.getTime()))),
      // ...
    });

    // Publish event (eventual consistency for other services)
    await this.eventPublisher.publish({
      eventId: uuidv4(),
      eventType: 'battle.created',
      eventVersion: '1.0.0',
      timestamp: new Date().toISOString(),
      data: {
        battleId: battle.id,
        systemId: battle.systemId.toString(),
        startTime: battle.startTime.toISOString(),
        // ... full battle data
      },
    });

    return battle;
  }
}

// Search Service eventually indexes battle (eventually consistent)
class SearchService {
  async onBattleCreated(event: BattleCreatedEvent): Promise<void> {
    // Index battle data in Typesense
    await this.searchClient.collections('battles').documents().create({
      id: event.data.battleId,
      systemId: event.data.systemId,
      systemName: event.data.systemName,
      startTime: new Date(event.data.startTime).getTime(),
      // ...
    });

    // Search results are now eventually consistent with Battle database
    // There may be a delay (seconds to minutes) before battle appears in search
  }
}
```

#### Pattern 2: Read-Your-Own-Writes Consistency

```typescript
// Frontend creates battle and wants to display it immediately
class BattleAPI {
  async createBattle(request: CreateBattleRequest): Promise<Battle> {
    // Create battle in Clusterer Service
    const battle = await this.clustererClient.post('/api/battles', request);

    // Return immediately (read-your-own-writes)
    // Battle is immediately visible to this client
    return battle;
  }

  async getBattle(battleId: string): Promise<Battle> {
    // Option 1: Read from Clusterer Service (immediate consistency)
    return await this.clustererClient.get(`/api/battles/${battleId}`);

    // Option 2: Read from Search Service (eventually consistent)
    // May return 404 if event hasn't been processed yet
    // Frontend should handle with retry or "Processing..." message
  }
}

// Frontend handling eventual consistency
async function displayBattle(battleId: string) {
  try {
    const battle = await api.getBattle(battleId);
    renderBattle(battle);
  } catch (error) {
    if (error.status === 404) {
      // Battle not yet indexed in search
      showMessage('Battle is being processed, please wait...');

      // Retry with exponential backoff
      setTimeout(() => displayBattle(battleId), 2000);
    }
  }
}
```

---

### 4. Distributed Transactions (Saga Pattern)

**Rule**: Avoid distributed transactions. Use sagas (choreography or orchestration) for multi-service operations.

**Why Critical**:
- Two-phase commit is slow and fragile
- Locks across services cause cascading failures
- Sagas provide eventual consistency with compensation

**Implementation Patterns**:

#### Pattern 1: Choreography-Based Saga (Event-Driven)

```typescript
// Scenario: Create battle → Index in search → Notify subscribers

// Step 1: Clusterer creates battle
class ClustererService {
  async createBattle(killmails: KillmailEventRecord[]): Promise<Battle> {
    const battle = await this.battleRepository.create(/* ... */);

    // Publish event (no knowledge of downstream services)
    await this.publisher.publish('battle.created', {
      eventId: uuidv4(),
      data: battle,
    });

    return battle;
  }
}

// Step 2: Search Service indexes battle
class SearchService {
  async onBattleCreated(event: BattleCreatedEvent): Promise<void> {
    try {
      await this.searchClient.index(event.data);

      // Publish success event
      await this.publisher.publish('battle.indexed', {
        eventId: uuidv4(),
        data: { battleId: event.data.battleId },
      });
    } catch (error) {
      // Publish failure event (compensation trigger)
      await this.publisher.publish('battle.indexing.failed', {
        eventId: uuidv4(),
        data: { battleId: event.data.battleId, error: error.message },
      });
      throw error;
    }
  }
}

// Step 3: Notification Service sends notifications
class NotificationService {
  async onBattleIndexed(event: BattleIndexedEvent): Promise<void> {
    const subscribers = await this.getSubscribers(event.data.battleId);

    await Promise.all(
      subscribers.map(sub => this.sendNotification(sub, event.data))
    );
  }

  // Compensation handler
  async onBattleIndexingFailed(event: BattleIndexingFailedEvent): Promise<void> {
    logger.error('Battle indexing failed, skipping notifications', {
      battleId: event.data.battleId,
    });
    // Don't send notifications for failed battles
  }
}
```

#### Pattern 2: Orchestration-Based Saga (Centralized Coordinator)

```typescript
// Saga orchestrator coordinates multi-step process
class BattleCreationSaga {
  constructor(
    private clusterer: ClustererClient,
    private search: SearchClient,
    private notifications: NotificationClient,
  ) {}

  async execute(request: CreateBattleRequest): Promise<BattleSagaResult> {
    const sagaId = uuidv4();
    const state: SagaState = { step: 0, rollbacks: [] };

    try {
      // Step 1: Create battle
      state.step = 1;
      const battle = await this.clusterer.createBattle(request);
      state.rollbacks.push(() => this.clusterer.deleteBattle(battle.id));

      // Step 2: Index in search
      state.step = 2;
      await this.search.indexBattle(battle);
      state.rollbacks.push(() => this.search.deleteBattle(battle.id));

      // Step 3: Send notifications
      state.step = 3;
      await this.notifications.notifySubscribers(battle);
      // No rollback needed (notifications are fire-and-forget)

      logger.info('Saga completed successfully', { sagaId, battleId: battle.id });
      return { success: true, battleId: battle.id };

    } catch (error) {
      logger.error('Saga failed, executing compensation', {
        sagaId,
        failedStep: state.step,
        error,
      });

      // Execute compensating transactions in reverse order
      for (const rollback of state.rollbacks.reverse()) {
        try {
          await rollback();
        } catch (rollbackError) {
          logger.error('Compensation failed', { sagaId, rollbackError });
          // Continue with other rollbacks
        }
      }

      return { success: false, error: error.message };
    }
  }
}
```

---

### 5. Timeouts and Circuit Breakers

**Rule**: All distributed calls MUST have timeouts. Use circuit breakers to prevent cascading failures.

**Why Critical**:
- Services can become slow or unresponsive
- Waiting forever causes resource exhaustion
- Cascading failures can take down entire system

**Implementation Patterns**:

#### Pattern 1: HTTP Client with Timeout

```typescript
// HTTP client with aggressive timeouts
class ClustererClient {
  private httpClient: AxiosInstance;

  constructor(baseURL: string) {
    this.httpClient = axios.create({
      baseURL,
      timeout: 5000, // 5 second timeout
      headers: {
        'Content-Type': 'application/json',
      },
    });

    // Retry with exponential backoff
    axiosRetry(this.httpClient, {
      retries: 3,
      retryDelay: axiosRetry.exponentialDelay,
      retryCondition: (error) => {
        // Retry on network errors and 5xx responses
        return axiosRetry.isNetworkOrIdempotentRequestError(error) ||
               (error.response?.status ?? 0) >= 500;
      },
    });
  }

  async getBattle(battleId: string): Promise<Battle> {
    try {
      const response = await this.httpClient.get(`/api/battles/${battleId}`);
      return response.data;
    } catch (error) {
      if (axios.isAxiosError(error)) {
        if (error.code === 'ECONNABORTED') {
          throw new TimeoutError(`Request timed out: GET /api/battles/${battleId}`);
        }
        if (error.response?.status === 404) {
          throw new NotFoundError(`Battle ${battleId} not found`);
        }
      }
      throw error;
    }
  }
}
```

#### Pattern 2: Circuit Breaker

```typescript
// Circuit breaker pattern using opossum
import CircuitBreaker from 'opossum';

class EnrichmentClient {
  private circuitBreaker: CircuitBreaker;

  constructor(private httpClient: AxiosInstance) {
    this.circuitBreaker = new CircuitBreaker(
      async (killmailId: bigint) => {
        return await this.httpClient.get(`/api/killmails/enriched/${killmailId}`);
      },
      {
        timeout: 3000, // 3 second timeout
        errorThresholdPercentage: 50, // Open circuit if 50% of requests fail
        resetTimeout: 30000, // Try again after 30 seconds
        rollingCountTimeout: 10000, // 10 second window for error calculation
      }
    );

    // Event handlers
    this.circuitBreaker.on('open', () => {
      logger.error('Circuit breaker opened for EnrichmentClient');
      // Alert operations team
    });

    this.circuitBreaker.on('halfOpen', () => {
      logger.info('Circuit breaker half-open, testing EnrichmentClient');
    });

    this.circuitBreaker.on('close', () => {
      logger.info('Circuit breaker closed, EnrichmentClient recovered');
    });

    this.circuitBreaker.fallback(() => {
      // Return cached or default data when circuit is open
      return { enrichmentUnavailable: true };
    });
  }

  async getEnrichedKillmail(killmailId: bigint): Promise<EnrichedKillmail> {
    try {
      const response = await this.circuitBreaker.fire(killmailId);
      return response.data;
    } catch (error) {
      if (error.message === 'Breaker is open') {
        logger.warn('Circuit breaker is open, using fallback', { killmailId });
        // Return cached data or throw specific error
        throw new ServiceUnavailableError('Enrichment service is temporarily unavailable');
      }
      throw error;
    }
  }
}
```

---

### 6. Bulkheads (Resource Isolation)

**Rule**: Isolate resources to prevent failures in one area from affecting others.

**Why Critical**:
- Thread pool exhaustion in one operation shouldn't block others
- Database connection pool exhaustion shouldn't take down entire service
- Rate limiting should be per-tenant or per-operation

**Implementation Patterns**:

#### Pattern 1: Separate Thread Pools

```typescript
// Separate thread pools for different operations
class BattleService {
  // High-priority operations (user-facing)
  private highPriorityPool = new WorkerPool({
    maxWorkers: 10,
    maxQueueSize: 100,
  });

  // Low-priority operations (background jobs)
  private lowPriorityPool = new WorkerPool({
    maxWorkers: 5,
    maxQueueSize: 1000,
  });

  async getBattle(battleId: string): Promise<Battle> {
    // Use high-priority pool for user-facing requests
    return await this.highPriorityPool.exec(async () => {
      return await this.battleRepository.findById(battleId);
    });
  }

  async reindexAllBattles(): Promise<void> {
    // Use low-priority pool for background jobs
    return await this.lowPriorityPool.exec(async () => {
      const battles = await this.battleRepository.findAll();
      for (const battle of battles) {
        await this.searchClient.index(battle);
      }
    });
  }
}
```

#### Pattern 2: Separate Database Connection Pools

```typescript
// Separate connection pools for reads and writes
class DatabaseManager {
  // Write pool (smaller, more controlled)
  private writePool = new Pool({
    host: 'postgres-primary',
    port: 5432,
    database: 'battles_db',
    user: 'battles_user',
    password: process.env.DB_PASSWORD,
    max: 10, // Maximum 10 write connections
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 5000,
  });

  // Read pool (larger, can scale with read replicas)
  private readPool = new Pool({
    host: 'postgres-replica',
    port: 5432,
    database: 'battles_db',
    user: 'battles_readonly',
    password: process.env.DB_PASSWORD,
    max: 50, // More read connections allowed
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 5000,
  });

  getWriteConnection(): Kysely<Database> {
    return new Kysely({ dialect: new PostgresDialect({ pool: this.writePool }) });
  }

  getReadConnection(): Kysely<Database> {
    return new Kysely({ dialect: new PostgresDialect({ pool: this.readPool }) });
  }
}

// Usage
class BattleRepository {
  async findById(id: string): Promise<Battle> {
    // Use read pool (won't exhaust write connections)
    const db = this.dbManager.getReadConnection();
    return await db.selectFrom('battles').where('id', '=', id).executeTakeFirst();
  }

  async create(battle: NewBattle): Promise<Battle> {
    // Use write pool
    const db = this.dbManager.getWriteConnection();
    return await db.insertInto('battles').values(battle).returningAll().executeTakeFirst();
  }
}
```

---

### 7. Observability (Distributed Tracing)

**Rule**: All distributed operations MUST be traceable across service boundaries.

**Why Critical**:
- Debugging distributed systems requires seeing full request flow
- Latency issues can be anywhere in the chain
- Causality tracking requires correlation IDs

**Implementation Patterns**:

#### Pattern 1: OpenTelemetry Distributed Tracing

```typescript
// Initialize OpenTelemetry
import { NodeSDK } from '@opentelemetry/sdk-node';
import { HttpInstrumentation } from '@opentelemetry/instrumentation-http';
import { ExpressInstrumentation } from '@opentelemetry/instrumentation-express';
import { KafkaJsInstrumentation } from 'opentelemetry-instrumentation-kafkajs';
import { JaegerExporter } from '@opentelemetry/exporter-jaeger';

const sdk = new NodeSDK({
  serviceName: 'clusterer-service',
  traceExporter: new JaegerExporter({
    endpoint: 'http://jaeger:14268/api/traces',
  }),
  instrumentations: [
    new HttpInstrumentation(),
    new ExpressInstrumentation(),
    new KafkaJsInstrumentation(),
  ],
});

sdk.start();

// Tracing is now automatic for HTTP and Kafka
// Each request gets a trace ID that propagates across services

// Manual span creation for custom operations
import { trace } from '@opentelemetry/api';

class ClustererService {
  async processBatch(batchSize: number): Promise<void> {
    const tracer = trace.getTracer('clusterer-service');

    const span = tracer.startSpan('processBatch', {
      attributes: {
        'batch.size': batchSize,
      },
    });

    try {
      const killmails = await this.fetchKillmails(batchSize);
      span.addEvent('killmails_fetched', { count: killmails.length });

      const battles = await this.clusterKillmails(killmails);
      span.addEvent('battles_created', { count: battles.length });

      await this.publishEvents(battles);
      span.addEvent('events_published');

      span.setStatus({ code: SpanStatusCode.OK });
    } catch (error) {
      span.recordException(error as Error);
      span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });
      throw error;
    } finally {
      span.end();
    }
  }
}
```

#### Pattern 2: Correlation IDs in Logs

```typescript
// Structured logging with correlation IDs
import { Logger } from 'pino';
import { v4 as uuidv4 } from 'uuid';

class RequestLogger {
  constructor(private logger: Logger) {}

  // Express middleware to add correlation ID
  middleware() {
    return (req: Request, res: Response, next: NextFunction) => {
      // Get correlation ID from header or generate new one
      const correlationId = req.headers['x-correlation-id'] || uuidv4();

      // Store in request context
      req.correlationId = correlationId;

      // Add to response headers
      res.setHeader('x-correlation-id', correlationId);

      // Create child logger with correlation ID
      req.log = this.logger.child({ correlationId });

      next();
    };
  }
}

// Kafka event handler with correlation ID
class BattleCreatedConsumer {
  async handle(event: BattleCreatedEvent): Promise<void> {
    // Extract correlation ID from event metadata
    const correlationId = event.metadata?.correlationId || event.eventId;

    const log = logger.child({ correlationId, eventId: event.eventId });

    log.info('Processing battle.created event', { battleId: event.data.battleId });

    try {
      await this.indexBattle(event.data);
      log.info('Battle indexed successfully');
    } catch (error) {
      log.error('Battle indexing failed', { error });
      throw error;
    }
  }
}

// Propagate correlation ID to downstream services
class ClustererClient {
  async createBattle(request: CreateBattleRequest, correlationId: string): Promise<Battle> {
    const response = await this.httpClient.post('/api/battles', request, {
      headers: {
        'x-correlation-id': correlationId, // Propagate to downstream service
      },
    });
    return response.data;
  }
}
```

---

### 8. Backpressure and Rate Limiting

**Rule**: Services MUST implement backpressure to prevent overload.

**Why Critical**:
- Unbounded queues cause memory exhaustion
- Overloaded services slow down, causing cascading failures
- Rate limiting prevents abuse and ensures fair resource allocation

**Implementation Patterns**:

#### Pattern 1: Kafka Consumer Backpressure

```typescript
class KafkaConsumer {
  async start(): Promise<void> {
    await this.consumer.run({
      // Control concurrency to prevent overload
      eachBatchAutoResolve: false,
      eachBatch: async ({ batch, resolveOffset, heartbeat, isStale }) => {
        const maxConcurrency = 10;

        for (let i = 0; i < batch.messages.length; i += maxConcurrency) {
          // Check if partition was revoked
          if (isStale()) break;

          // Process batch in chunks
          const chunk = batch.messages.slice(i, i + maxConcurrency);

          await Promise.all(
            chunk.map(async (message) => {
              try {
                await this.processMessage(message);
                // Commit offset after successful processing
                await resolveOffset(message.offset);
              } catch (error) {
                logger.error('Message processing failed', { error });
                // Don't commit - message will be retried
              }
            })
          );

          // Send heartbeat to avoid rebalance
          await heartbeat();
        }
      },
    });
  }
}
```

#### Pattern 2: API Rate Limiting

```typescript
// Rate limiting middleware using Redis
import rateLimit from 'express-rate-limit';
import RedisStore from 'rate-limit-redis';

const apiLimiter = rateLimit({
  store: new RedisStore({
    client: redisClient,
    prefix: 'rl:api:',
  }),
  windowMs: 60 * 1000, // 1 minute window
  max: 100, // 100 requests per minute per IP
  standardHeaders: true,
  legacyHeaders: false,
  handler: (req, res) => {
    res.status(429).json({
      error: 'RATE_LIMIT_EXCEEDED',
      message: 'Too many requests, please try again later',
      retryAfter: req.rateLimit.resetTime,
    });
  },
});

app.use('/api/', apiLimiter);

// Per-user rate limiting
const userLimiter = rateLimit({
  store: new RedisStore({
    client: redisClient,
    prefix: 'rl:user:',
  }),
  keyGenerator: (req) => req.user?.id || req.ip, // Use user ID if authenticated
  windowMs: 60 * 1000,
  max: 200, // Higher limit for authenticated users
});

app.use('/api/battles', userLimiter);
```

---

## BattleScope Distributed Design Patterns

### Pattern 1: Killmail Ingestion Pipeline

**Distributed Flow**:
```
zKillboard → Ingest Service → Kafka → Enrichment Service → Kafka → Clusterer Service
```

**Guarantees**:
- **At-least-once delivery**: Kafka consumer commits only after successful processing
- **Idempotency**: Killmail ID used as natural deduplication key
- **Eventual consistency**: Enrichment and clustering happen asynchronously
- **Fault tolerance**: Each service can fail independently, Kafka retries

**Implementation**:
```typescript
// Ingest Service
class IngestService {
  async pollZKillboard(): Promise<void> {
    const killmail = await this.zkillboard.poll();

    // Idempotent insert
    await this.repository.insert(killmail); // Unique constraint on killmail_id

    // Publish event (at-least-once)
    await this.publisher.publish('killmail.ingested', {
      eventId: uuidv4(),
      data: killmail,
    });
  }
}

// Enrichment Service
class EnrichmentService {
  async onKillmailIngested(event: KillmailIngestedEvent): Promise<void> {
    // Idempotent check
    if (await this.isAlreadyEnriched(event.data.killmailId)) {
      return;
    }

    // Enrich with ESI data (with retries and circuit breaker)
    const enriched = await this.enrichWithESI(event.data);

    // Publish enriched event
    await this.publisher.publish('killmail.enriched', {
      eventId: uuidv4(),
      data: enriched,
    });
  }
}

// Clusterer Service
class ClustererService {
  async onKillmailEnriched(event: KillmailEnrichedEvent): Promise<void> {
    // Idempotent clustering
    const existingBattle = await this.findExistingBattle(event.data);

    if (existingBattle) {
      // Update existing battle (idempotent with UPSERT)
      await this.updateBattle(existingBattle.id, event.data);
    } else {
      // Create new battle
      const battle = await this.createBattle([event.data]);
      await this.publisher.publish('battle.created', { data: battle });
    }
  }
}
```

---

### Pattern 2: Battle Query with Fallback

**Distributed Flow**:
```
Frontend → API Gateway → Clusterer Service (primary)
                      ↓
                    Search Service (fallback for list queries)
```

**Guarantees**:
- **Read-your-own-writes**: Direct queries to Clusterer for single battle
- **Eventual consistency**: List queries from Search Service may lag
- **Fallback**: If Clusterer is down, use cached data from Search

**Implementation**:
```typescript
class BattleAPI {
  async getBattle(battleId: string): Promise<Battle> {
    try {
      // Try Clusterer Service first (source of truth)
      return await this.clustererClient.get(`/api/battles/${battleId}`);
    } catch (error) {
      if (error instanceof TimeoutError || error instanceof ServiceUnavailableError) {
        // Fallback to Search Service
        logger.warn('Clusterer unavailable, using search fallback', { battleId });
        return await this.searchClient.get(`/api/search/battles/${battleId}`);
      }
      throw error;
    }
  }

  async listBattles(params: BattleListParams): Promise<BattleList> {
    // List queries always go to Search Service (optimized for filtering)
    try {
      return await this.searchClient.get('/api/search/battles', { params });
    } catch (error) {
      // If search is down, fallback to Clusterer (slower, but works)
      logger.warn('Search unavailable, using clusterer fallback');
      return await this.clustererClient.get('/api/battles', { params });
    }
  }
}
```

---

### Pattern 3: Saga for Battle Deletion

**Distributed Flow**:
```
Delete Battle → Clusterer → Kafka → Search Service
                                  ↓
                                Notification Service
```

**Guarantees**:
- **Compensation**: If deletion fails in one service, compensate in others
- **Idempotency**: Deletion operations are naturally idempotent
- **Eventual consistency**: Search index eventually reflects deletion

**Implementation**:
```typescript
// Clusterer Service publishes deletion event
class ClustererService {
  async deleteBattle(battleId: string): Promise<void> {
    // Soft delete (preserve history)
    await this.battleRepository.update(battleId, { deletedAt: new Date() });

    // Publish deletion event
    await this.publisher.publish('battle.deleted', {
      eventId: uuidv4(),
      data: { battleId },
    });
  }
}

// Search Service removes from index
class SearchService {
  async onBattleDeleted(event: BattleDeletedEvent): Promise<void> {
    try {
      await this.searchClient.collections('battles').documents(event.data.battleId).delete();
      logger.info('Battle removed from search index', { battleId: event.data.battleId });
    } catch (error) {
      if (error.httpStatus === 404) {
        // Already deleted (idempotent)
        return;
      }
      throw error;
    }
  }
}

// Notification Service stops notifications
class NotificationService {
  async onBattleDeleted(event: BattleDeletedEvent): Promise<void> {
    // Remove all subscriptions for this battle
    await this.subscriptionRepository.deleteByBattleId(event.data.battleId);
    logger.info('Battle subscriptions removed', { battleId: event.data.battleId });
  }
}
```

---

## Anti-Patterns to Avoid

### ❌ Non-Idempotent Operations

**Bad**:
```typescript
// Incrementing without checking
async addKillToBattle(battleId: string): Promise<void> {
  await this.db
    .updateTable('battles')
    .set({ totalKills: sql`total_kills + 1` }) // Duplicate calls increment multiple times
    .where('id', '=', battleId)
    .execute();
}
```

**Good**:
```typescript
// Idempotent with deduplication
async addKillToBattle(battleId: string, killmailId: bigint): Promise<void> {
  // Check if already processed
  const exists = await this.db
    .selectFrom('battle_killmails')
    .where('battleId', '=', battleId)
    .where('killmailId', '=', killmailId)
    .executeTakeFirst();

  if (exists) return; // Idempotent - already counted

  // Insert killmail and increment
  await this.db.transaction().execute(async (trx) => {
    await trx
      .insertInto('battle_killmails')
      .values({ battleId, killmailId })
      .execute();

    await trx
      .updateTable('battles')
      .set({ totalKills: sql`total_kills + 1` })
      .where('id', '=', battleId)
      .execute();
  });
}
```

---

### ❌ Missing Timeouts

**Bad**:
```typescript
// No timeout - can hang forever
const response = await axios.get('http://external-service/api/data');
```

**Good**:
```typescript
// Explicit timeout with retry
const response = await axios.get('http://external-service/api/data', {
  timeout: 5000,
  retry: 3,
});
```

---

### ❌ Synchronous Cascade

**Bad**:
```typescript
// Synchronous calls to multiple services (slow, fragile)
async createBattle(request: CreateBattleRequest): Promise<Battle> {
  const battle = await this.clustererClient.createBattle(request);
  await this.searchClient.indexBattle(battle); // Blocks
  await this.notificationClient.notifySubscribers(battle); // Blocks
  return battle;
}
```

**Good**:
```typescript
// Event-driven (fast, resilient)
async createBattle(request: CreateBattleRequest): Promise<Battle> {
  const battle = await this.clustererClient.createBattle(request);
  // Clusterer publishes event, Search and Notification consume asynchronously
  return battle; // Return immediately
}
```

---

### ❌ Unbounded Queues

**Bad**:
```typescript
// Unbounded queue causes memory exhaustion
const queue: Task[] = [];
while (true) {
  const task = await fetchTask();
  queue.push(task); // Grows forever if processing is slow
}
```

**Good**:
```typescript
// Bounded queue with backpressure
const queue = new BoundedQueue<Task>({ maxSize: 1000 });

while (true) {
  const task = await fetchTask();

  if (queue.isFull()) {
    // Apply backpressure
    logger.warn('Queue full, pausing ingestion');
    await sleep(1000);
    continue;
  }

  queue.push(task);
}
```

---

### ❌ Ignoring Partial Failures

**Bad**:
```typescript
// All-or-nothing - one failure breaks everything
await Promise.all([
  this.indexBattle(battle),
  this.sendNotifications(battle),
  this.updateCache(battle),
]);
```

**Good**:
```typescript
// Handle partial failures gracefully
const results = await Promise.allSettled([
  this.indexBattle(battle),
  this.sendNotifications(battle),
  this.updateCache(battle),
]);

results.forEach((result, index) => {
  if (result.status === 'rejected') {
    logger.error(`Operation ${index} failed`, { error: result.reason });
    // Continue with other operations
  }
});
```

---

## Validation Checklist

Before deploying any distributed operation, verify:

### Idempotency
- [ ] Operation can be safely retried without side effects
- [ ] Deduplication mechanism in place (idempotency keys, unique constraints)
- [ ] Database operations use UPSERT or ON CONFLICT
- [ ] Event consumers check for duplicate event IDs

### Fault Tolerance
- [ ] All network calls have timeouts (typically 3-5 seconds)
- [ ] Circuit breakers in place for external dependencies
- [ ] Retry logic with exponential backoff
- [ ] Graceful degradation when dependencies fail

### Consistency
- [ ] Eventual consistency is acceptable (or explained why not)
- [ ] Read-your-own-writes guarantee where needed
- [ ] No distributed transactions (or justified why needed)
- [ ] Saga pattern for multi-service operations

### Observability
- [ ] Distributed tracing enabled (OpenTelemetry)
- [ ] Correlation IDs propagated across services
- [ ] Structured logging with context
- [ ] Metrics for latency, error rate, throughput

### Backpressure
- [ ] Bounded queues with overflow handling
- [ ] Rate limiting on public APIs
- [ ] Consumer concurrency limits
- [ ] Resource isolation (bulkheads)

---

## Summary: The Golden Rules

1. **Idempotency First** - Every operation must be safely repeatable
2. **At-Least-Once + Idempotency = Exactly-Once** - Message delivery guarantees
3. **Eventual Consistency** - Accept delays, don't force immediate consistency
4. **No Distributed Transactions** - Use sagas for multi-service operations
5. **Timeouts Everywhere** - Network calls must have deadlines
6. **Circuit Breakers** - Prevent cascading failures
7. **Bulkheads** - Isolate resources to contain failures
8. **Distributed Tracing** - Observe full request flow across services
9. **Backpressure** - Prevent overload with bounded queues
10. **Graceful Degradation** - Continue operating when dependencies fail

---

## How Claude Should Use This Skill

When I (Claude) am:

- **Designing inter-service communication**: Ensure idempotency and timeouts
- **Implementing event handlers**: Add deduplication and validation
- **Creating HTTP endpoints**: Add rate limiting and circuit breakers
- **Writing Kafka consumers**: Implement at-least-once with idempotent processing
- **Handling failures**: Design compensation logic (saga pattern)
- **Adding external calls**: Wrap with timeouts, retries, circuit breakers
- **Reviewing code**: Flag non-idempotent operations and missing timeouts

**If a distributed operation doesn't follow these principles, I should STOP and redesign it.**

---

---

## 9. Retry Strategies and Exponential Backoff

**Rule**: Failed operations MUST be retried with exponential backoff and jitter.

**Why Critical**:
- Immediate retries amplify load during outages
- Linear backoff isn't aggressive enough for transient failures
- Jitter prevents thundering herd problem

**Implementation Patterns**:

#### Pattern 1: Exponential Backoff with Jitter

```typescript
// Exponential backoff with full jitter
async function retryWithBackoff<T>(
  operation: () => Promise<T>,
  options: {
    maxRetries: number;
    initialDelayMs: number;
    maxDelayMs: number;
    shouldRetry?: (error: Error) => boolean;
  },
): Promise<T> {
  const { maxRetries, initialDelayMs, maxDelayMs, shouldRetry } = options;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      const isLastAttempt = attempt === maxRetries;
      const shouldRetryError = shouldRetry ? shouldRetry(error as Error) : true;

      if (isLastAttempt || !shouldRetryError) {
        throw error;
      }

      // Calculate exponential backoff: min(maxDelay, initialDelay * 2^attempt)
      const exponentialDelay = Math.min(
        maxDelayMs,
        initialDelayMs * Math.pow(2, attempt),
      );

      // Add full jitter: random value between 0 and exponentialDelay
      const jitter = Math.random() * exponentialDelay;

      logger.warn('Operation failed, retrying with backoff', {
        attempt: attempt + 1,
        maxRetries,
        delayMs: Math.round(jitter),
        error: (error as Error).message,
      });

      await sleep(jitter);
    }
  }

  throw new Error('Retry logic error'); // Should never reach here
}

// Usage
const enrichedKillmail = await retryWithBackoff(
  () => this.esiClient.getShipType(shipTypeId),
  {
    maxRetries: 5,
    initialDelayMs: 100,
    maxDelayMs: 30000, // Cap at 30 seconds
    shouldRetry: (error) => {
      // Only retry on transient errors
      return error instanceof NetworkError ||
             error instanceof TimeoutError ||
             (error instanceof HttpError && error.statusCode >= 500);
    },
  },
);
```

#### Pattern 2: Retry with Circuit Breaker

```typescript
// Combine retry logic with circuit breaker
class ResilientHttpClient {
  private circuitBreaker: CircuitBreaker;

  constructor(baseURL: string) {
    this.circuitBreaker = new CircuitBreaker(
      async (config: RequestConfig) => {
        return await this.executeWithRetry(config);
      },
      {
        timeout: 5000,
        errorThresholdPercentage: 50,
        resetTimeout: 30000,
      },
    );
  }

  private async executeWithRetry(config: RequestConfig): Promise<any> {
    return await retryWithBackoff(
      () => axios.request(config),
      {
        maxRetries: 3,
        initialDelayMs: 200,
        maxDelayMs: 5000,
        shouldRetry: (error) => {
          if (axios.isAxiosError(error)) {
            // Retry on network errors and 5xx responses
            return !error.response || error.response.status >= 500;
          }
          return true;
        },
      },
    );
  }

  async get(url: string): Promise<any> {
    return await this.circuitBreaker.fire({ method: 'GET', url });
  }
}
```

---

## 10. Dead Letter Queues

**Rule**: Failed events MUST be routed to dead letter queues for manual inspection.

**Why Critical**:
- Some failures are permanent (malformed data, logic errors)
- Infinite retries waste resources and cause lag
- Manual inspection helps identify systemic issues

**Implementation Patterns**:

#### Pattern 1: Kafka Dead Letter Topic

```typescript
class KafkaEventConsumer {
  private readonly maxRetries = 3;
  private readonly deadLetterTopic = 'dead-letter-queue';

  async processEvent(event: Event): Promise<void> {
    const retryCount = event.metadata?.retryCount || 0;

    try {
      // Validate event schema
      if (!this.validateEvent(event)) {
        throw new ValidationError('Event schema validation failed');
      }

      // Process event
      await this.handleEvent(event);

      logger.info('Event processed successfully', { eventId: event.eventId });
    } catch (error) {
      logger.error('Event processing failed', {
        eventId: event.eventId,
        retryCount,
        error: (error as Error).message,
      });

      if (retryCount >= this.maxRetries) {
        // Send to dead letter queue
        await this.sendToDeadLetterQueue(event, error as Error);
        logger.error('Event sent to dead letter queue', { eventId: event.eventId });

        // Don't throw - commit offset to skip this message
        return;
      }

      // Increment retry count and retry
      event.metadata = {
        ...event.metadata,
        retryCount: retryCount + 1,
        lastError: (error as Error).message,
        lastErrorAt: new Date().toISOString(),
      };

      throw error; // Kafka will redeliver
    }
  }

  private async sendToDeadLetterQueue(event: Event, error: Error): Promise<void> {
    await this.producer.send({
      topic: this.deadLetterTopic,
      messages: [
        {
          key: event.eventId,
          value: JSON.stringify({
            originalEvent: event,
            error: {
              message: error.message,
              stack: error.stack,
              name: error.constructor.name,
            },
            failedAt: new Date().toISOString(),
            retryCount: event.metadata?.retryCount || 0,
          }),
          headers: {
            'original-topic': event.metadata?.originalTopic || 'unknown',
            'error-type': error.constructor.name,
          },
        },
      ],
    });

    // Alert operations team
    await this.alerting.sendAlert({
      severity: 'warning',
      title: 'Event sent to dead letter queue',
      message: `Event ${event.eventId} failed after ${this.maxRetries} retries`,
      context: { eventId: event.eventId, error: error.message },
    });
  }

  // Admin endpoint to replay dead letter events
  async replayDeadLetterEvent(eventId: string): Promise<void> {
    const deadLetter = await this.fetchFromDeadLetterQueue(eventId);

    // Reset retry count
    deadLetter.originalEvent.metadata.retryCount = 0;

    // Republish to original topic
    await this.producer.send({
      topic: deadLetter.originalEvent.metadata.originalTopic,
      messages: [{ value: JSON.stringify(deadLetter.originalEvent) }],
    });

    logger.info('Dead letter event replayed', { eventId });
  }
}
```

---

## 11. Event Ordering and Causality

**Rule**: Event ordering MUST be preserved when causality matters.

**Why Critical**:
- Events can arrive out of order due to network delays
- Parallel processing breaks ordering guarantees
- Causality violations cause incorrect state

**Implementation Patterns**:

#### Pattern 1: Kafka Partitioning by Entity ID

```typescript
// Ensure events for same battle go to same partition (preserves ordering)
class BattleEventPublisher {
  async publishBattleCreated(battle: Battle): Promise<void> {
    await this.producer.send({
      topic: 'battle.created',
      messages: [
        {
          key: battle.id, // Same battleId always goes to same partition
          value: JSON.stringify({
            eventId: uuidv4(),
            eventType: 'battle.created',
            timestamp: new Date().toISOString(),
            data: battle,
          }),
        },
      ],
    });
  }

  async publishBattleUpdated(battle: Battle): Promise<void> {
    await this.producer.send({
      topic: 'battle.updated',
      messages: [
        {
          key: battle.id, // Same partition as battle.created
          value: JSON.stringify({
            eventId: uuidv4(),
            eventType: 'battle.updated',
            timestamp: new Date().toISOString(),
            data: battle,
          }),
        },
      ],
    });
  }
}

// Consumer processes events in order per partition
class BattleEventConsumer {
  async start(): Promise<void> {
    await this.consumer.run({
      eachMessage: async ({ topic, partition, message }) => {
        // Events with same key (battleId) are processed in order
        const event = JSON.parse(message.value!.toString());
        await this.handleEvent(event);
      },
    });
  }
}
```

#### Pattern 2: Vector Clocks for Causality Tracking

```typescript
// Track causality with vector clocks
interface VectorClock {
  [serviceId: string]: number;
}

interface CausalEvent {
  eventId: string;
  eventType: string;
  timestamp: string;
  vectorClock: VectorClock; // Causality tracking
  data: any;
}

class CausalEventPublisher {
  private localClock: VectorClock = {};
  private readonly serviceId: string;

  constructor(serviceId: string) {
    this.serviceId = serviceId;
    this.localClock[serviceId] = 0;
  }

  async publish(eventType: string, data: any): Promise<void> {
    // Increment local clock
    this.localClock[this.serviceId]++;

    const event: CausalEvent = {
      eventId: uuidv4(),
      eventType,
      timestamp: new Date().toISOString(),
      vectorClock: { ...this.localClock }, // Copy current clock
      data,
    };

    await this.producer.send({
      topic: eventType,
      messages: [{ value: JSON.stringify(event) }],
    });
  }

  // Update clock when receiving event
  receiveEvent(event: CausalEvent): void {
    // Merge vector clocks
    for (const [serviceId, timestamp] of Object.entries(event.vectorClock)) {
      this.localClock[serviceId] = Math.max(
        this.localClock[serviceId] || 0,
        timestamp,
      );
    }
    // Increment own clock
    this.localClock[this.serviceId]++;
  }

  // Check if event A happened before event B
  happenedBefore(eventA: CausalEvent, eventB: CausalEvent): boolean {
    for (const serviceId of Object.keys(eventA.vectorClock)) {
      if (eventA.vectorClock[serviceId] > (eventB.vectorClock[serviceId] || 0)) {
        return false; // A did not happen before B
      }
    }
    return true; // A happened before B
  }
}
```

---

## 12. Data Consistency Patterns

**Rule**: Choose appropriate consistency model based on requirements.

**Why Critical**:
- Strong consistency is slow and fragile in distributed systems
- Eventual consistency requires careful design
- Different data has different consistency requirements

**Consistency Models**:

#### Strong Consistency (Rare, Expensive)

```typescript
// Use distributed locks for strong consistency (avoid if possible)
class BattleService {
  async updateBattleWithLock(battleId: string, updates: Partial<Battle>): Promise<Battle> {
    const lock = await this.redlock.acquire([`lock:battle:${battleId}`], 5000);

    try {
      // Read current state
      const battle = await this.battleRepository.findById(battleId);

      // Make decision based on current state
      if (battle.status === 'closed') {
        throw new Error('Cannot update closed battle');
      }

      // Update
      const updated = await this.battleRepository.update(battleId, updates);

      // Publish event
      await this.publisher.publish('battle.updated', updated);

      return updated;
    } finally {
      await lock.release();
    }
  }
}
```

#### Eventual Consistency (Preferred)

```typescript
// Eventual consistency with conflict resolution
class BattleRepository {
  async updateBattle(battleId: string, updates: Partial<Battle>): Promise<Battle> {
    // Optimistic locking with version field
    const updated = await this.db
      .updateTable('battles')
      .set({
        ...updates,
        version: sql`version + 1`, // Increment version
        updatedAt: new Date(),
      })
      .where('id', '=', battleId)
      .where('version', '=', updates.expectedVersion) // Compare-and-swap
      .returningAll()
      .executeTakeFirst();

    if (!updated) {
      // Conflict detected - another update happened
      throw new OptimisticLockError(
        `Battle ${battleId} was modified by another process`,
      );
    }

    return updated;
  }
}

// Consumer handles eventual consistency
class BattleSearchIndexer {
  async onBattleUpdated(event: BattleUpdatedEvent): Promise<void> {
    // Check if this update is newer than what we have
    const current = await this.searchClient.getDocument('battles', event.data.battleId);

    if (current && current.version >= event.data.version) {
      logger.info('Ignoring stale update', {
        battleId: event.data.battleId,
        currentVersion: current.version,
        eventVersion: event.data.version,
      });
      return; // Skip stale update
    }

    // Apply update
    await this.searchClient.updateDocument('battles', event.data.battleId, {
      ...event.data,
      indexedAt: new Date(),
    });
  }
}
```

#### Causal Consistency (Middle Ground)

```typescript
// Preserve causality but allow concurrent updates
class BattleParticipantTracker {
  private vectorClock: VectorClock = {};

  async addParticipant(battleId: string, participant: Participant): Promise<void> {
    // Increment local clock
    this.vectorClock[this.serviceId]++;

    await this.repository.insert({
      battleId,
      characterId: participant.characterId,
      joinedAt: new Date(),
      vectorClock: { ...this.vectorClock }, // Attach causality metadata
    });

    // Publish with vector clock
    await this.publisher.publish('participant.joined', {
      battleId,
      participant,
      vectorClock: this.vectorClock,
    });
  }

  // Consumer ensures causal ordering
  async onParticipantJoined(event: ParticipantJoinedEvent): Promise<void> {
    // Check if we've seen all causally preceding events
    if (!this.hasSeenAllPrecedingEvents(event.vectorClock)) {
      // Buffer this event until preceding events arrive
      await this.bufferEvent(event);
      return;
    }

    // Process event
    await this.indexParticipant(event.data);

    // Update local clock
    this.mergeVectorClock(event.vectorClock);

    // Check if buffered events can now be processed
    await this.processBufferedEvents();
  }
}
```

---

## 13. Graceful Degradation and Fallbacks

**Rule**: Services MUST degrade gracefully when dependencies fail.

**Why Critical**:
- Cascading failures take down entire system
- Users prefer degraded functionality over complete failure
- Non-critical features shouldn't block critical ones

**Implementation Patterns**:

#### Pattern 1: Fallback Chain

```typescript
class BattleEnrichmentService {
  async enrichBattle(battle: Battle): Promise<EnrichedBattle> {
    // Try enrichment with priority order
    const enrichedData = await this.enrichWithFallback(battle);

    return {
      ...battle,
      ...enrichedData,
    };
  }

  private async enrichWithFallback(battle: Battle): Promise<Partial<EnrichedBattle>> {
    try {
      // Priority 1: ESI API (real-time, most accurate)
      return await this.enrichFromESI(battle);
    } catch (error) {
      logger.warn('ESI enrichment failed, trying cache', { error });

      try {
        // Priority 2: Redis cache (fast, stale)
        return await this.enrichFromCache(battle);
      } catch (cacheError) {
        logger.warn('Cache enrichment failed, using minimal data', { cacheError });

        // Priority 3: Minimal data (always succeeds)
        return {
          systemName: `System ${battle.systemId}`,
          enrichmentStatus: 'degraded',
        };
      }
    }
  }
}
```

#### Pattern 2: Feature Toggles

```typescript
// Feature flags for graceful degradation
class FeatureFlags {
  private flags: Map<string, boolean> = new Map();

  constructor(private redis: Redis) {}

  async isEnabled(feature: string): Promise<boolean> {
    // Check Redis for feature flag
    const value = await this.redis.get(`feature:${feature}`);
    return value === 'true';
  }

  async disable(feature: string): Promise<void> {
    await this.redis.set(`feature:${feature}`, 'false');
    logger.info('Feature disabled', { feature });
  }
}

// Use feature flags to disable non-critical features during incidents
class BattleAPI {
  async getBattle(battleId: string): Promise<Battle> {
    const battle = await this.clustererClient.get(`/api/battles/${battleId}`);

    // Optional: Add participant details (can be slow)
    if (await this.featureFlags.isEnabled('battle-participants')) {
      try {
        battle.participants = await this.getParticipants(battleId);
      } catch (error) {
        logger.warn('Failed to load participants, continuing without', { error });
        // Don't fail entire request - degrade gracefully
      }
    }

    // Optional: Add statistics (requires heavy computation)
    if (await this.featureFlags.isEnabled('battle-statistics')) {
      try {
        battle.statistics = await this.calculateStatistics(battleId);
      } catch (error) {
        logger.warn('Failed to calculate statistics, continuing without', { error });
      }
    }

    return battle;
  }
}
```

---

## 14. Health Checks and Readiness Probes

**Rule**: Services MUST expose health and readiness endpoints for orchestration.

**Why Critical**:
- Kubernetes needs to know when to route traffic
- Load balancers need to detect unhealthy instances
- Auto-scaling depends on accurate health status

**Implementation Patterns**:

#### Pattern 1: Liveness and Readiness Probes

```typescript
class HealthCheckController {
  // Liveness probe: Is the process alive?
  // If fails, Kubernetes will restart the pod
  async liveness(req: Request, res: Response): Promise<void> {
    res.status(200).json({
      status: 'ok',
      timestamp: new Date().toISOString(),
    });
  }

  // Readiness probe: Is the service ready to handle traffic?
  // If fails, Kubernetes removes pod from service endpoints
  async readiness(req: Request, res: Response): Promise<void> {
    const checks = await Promise.allSettled([
      this.checkDatabase(),
      this.checkKafka(),
      this.checkRedis(),
    ]);

    const allHealthy = checks.every((check) => check.status === 'fulfilled');

    if (allHealthy) {
      res.status(200).json({
        status: 'ready',
        checks: checks.map((c, i) => ({
          name: ['database', 'kafka', 'redis'][i],
          status: c.status === 'fulfilled' ? 'healthy' : 'unhealthy',
        })),
      });
    } else {
      res.status(503).json({
        status: 'not_ready',
        checks: checks.map((c, i) => ({
          name: ['database', 'kafka', 'redis'][i],
          status: c.status === 'fulfilled' ? 'healthy' : 'unhealthy',
          error: c.status === 'rejected' ? c.reason.message : undefined,
        })),
      });
    }
  }

  // Startup probe: Has the service finished initialization?
  // Prevents premature liveness checks during slow startup
  async startup(req: Request, res: Response): Promise<void> {
    if (this.isInitialized) {
      res.status(200).json({ status: 'initialized' });
    } else {
      res.status(503).json({
        status: 'initializing',
        progress: this.initializationProgress,
      });
    }
  }

  private async checkDatabase(): Promise<void> {
    const timeout = 2000; // 2 second timeout
    await Promise.race([
      this.db.selectFrom('battles').select('id').limit(1).execute(),
      sleep(timeout).then(() => {
        throw new Error('Database health check timed out');
      }),
    ]);
  }

  private async checkKafka(): Promise<void> {
    // Check if Kafka consumer is connected
    if (!this.kafkaConsumer.isConnected()) {
      throw new Error('Kafka consumer not connected');
    }
  }

  private async checkRedis(): Promise<void> {
    await this.redis.ping();
  }
}

// Kubernetes deployment with probes
/**
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clusterer-service
spec:
  template:
    spec:
      containers:
      - name: clusterer
        image: clusterer-service:latest
        ports:
        - containerPort: 3000
        livenessProbe:
          httpGet:
            path: /health/liveness
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 2
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health/readiness
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 2
        startupProbe:
          httpGet:
            path: /health/startup
            port: 3000
          initialDelaySeconds: 0
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 30 # Allow 150 seconds for startup
*/
```

---

## 15. Statelessness and Session Affinity

**Rule**: Services SHOULD be stateless. If stateful, use session affinity carefully.

**Why Critical**:
- Stateless services scale horizontally trivially
- Stateful services require coordination and are fragile
- Session affinity reduces load balancer effectiveness

**Implementation Patterns**:

#### Pattern 1: Externalize State

```typescript
// Bad: In-memory state
class BattleService {
  private cache = new Map<string, Battle>(); // Doesn't scale

  async getBattle(battleId: string): Promise<Battle> {
    if (this.cache.has(battleId)) {
      return this.cache.get(battleId)!;
    }
    // ...
  }
}

// Good: Externalized state
class BattleService {
  constructor(private redis: Redis, private db: Kysely<Database>) {}

  async getBattle(battleId: string): Promise<Battle> {
    // Check distributed cache
    const cached = await this.redis.get(`battle:${battleId}`);
    if (cached) {
      return JSON.parse(cached);
    }

    // Load from database
    const battle = await this.db
      .selectFrom('battles')
      .where('id', '=', battleId)
      .executeTakeFirst();

    // Cache for future requests (any pod can serve)
    await this.redis.setex(`battle:${battleId}`, 300, JSON.stringify(battle));

    return battle;
  }
}
```

#### Pattern 2: Sticky Sessions (When Necessary)

```typescript
// WebSocket connections require session affinity
class NotificationService {
  private connections = new Map<string, WebSocket>(); // Pod-local state

  async handleWebSocketConnection(ws: WebSocket, userId: string): Promise<void> {
    this.connections.set(userId, ws);

    ws.on('close', () => {
      this.connections.delete(userId);
    });

    // Register in Redis for distributed routing
    await this.redis.hset('ws:connections', userId, this.podId);
  }

  async sendNotification(userId: string, notification: Notification): Promise<void> {
    // Check if user connected to this pod
    const localWs = this.connections.get(userId);
    if (localWs) {
      localWs.send(JSON.stringify(notification));
      return;
    }

    // Check which pod has the user's connection
    const targetPodId = await this.redis.hget('ws:connections', userId);
    if (targetPodId && targetPodId !== this.podId) {
      // Forward to correct pod via Redis pub/sub
      await this.redis.publish(`pod:${targetPodId}:notifications`, JSON.stringify({
        userId,
        notification,
      }));
    }
  }
}

// Kubernetes service with session affinity
/**
apiVersion: v1
kind: Service
metadata:
  name: notification-service
spec:
  sessionAffinity: ClientIP # Sticky sessions based on client IP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600 # 1 hour
  ports:
  - port: 3000
    targetPort: 3000
*/
```

---

## References

- **Designing Data-Intensive Applications** (Martin Kleppmann)
- **Release It!** (Michael Nygard) - Circuit breakers, bulkheads
- **Building Microservices** (Sam Newman) - Distributed systems patterns
- **CAP Theorem** (Eric Brewer)
- **Saga Pattern** (Hector Garcia-Molina, Kenneth Salem)
- **Two Generals Problem** - Why distributed consensus is hard
- **OpenTelemetry** - Distributed tracing standard
- **Exponential Backoff** - AWS Architecture Blog
- **Vector Clocks** - Leslie Lamport's work on distributed time
- **PACELC Theorem** - Extension of CAP theorem (Consistency vs Latency trade-off)
